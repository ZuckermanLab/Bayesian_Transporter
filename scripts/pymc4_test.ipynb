{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on PyMC v4.0.0b6\n"
     ]
    }
   ],
   "source": [
    "import aesara\n",
    "import aesara.tensor as at\n",
    "import arviz as az\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "from datetime import datetime\n",
    "import os\n",
    "import json\n",
    "import tellurium as te\n",
    "import scipy\n",
    "\n",
    "print(f\"Running on PyMC v{pm.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### log-likelihood functions\n",
    "\n",
    "def calc_norm_log_like(mu,sigma,X):\n",
    "    ''' calculates the Normal log-likelihood function: -[(n/2)ln(2pi*sigma^2)]-[sum((X-mu)^2)/(2*sigma^2)]\n",
    "    ref: https://www.statlect.com/fundamentals-of-statistics/normal-distribution-maximum-likelihood \n",
    "    '''\n",
    "    # fix this - remove loop\n",
    "    n = len(X)\n",
    "    f1 = -1*(n/2)*np.log(2*np.pi*sigma**2)\n",
    "    f2_a = -1/(2*sigma**2)\n",
    "    f2_b = 0 \n",
    "    for i in range(n):\n",
    "        f2_b += (X[i]-mu[i])**2\n",
    "    f2 = f2_a*f2_b\n",
    "    log_likelihood = f1+f2\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "def calc_log_like(K,y_obs,m):\n",
    "    '''calculates the log likelihood of a transporter tellurium ODE model m, given data y_obs, and parameters K\n",
    "    '''\n",
    "    #m = te.loada(ms)\n",
    "    idx_list = [0,2,4,6,8]  # index of rate pairs used to set attribute, last rate omitted - fix this later \n",
    "    m.resetToOrigin()\n",
    "    m.H_out = 5e-7\n",
    "    m.integrator.absolute_tolerance = 1e-18\n",
    "    m.integrator.relative_tolerance = 1e-12\n",
    "\n",
    "    # update tellurium model parameter values (rate constants)\n",
    "    for i, idx in enumerate(idx_list):\n",
    "        setattr(m, f'k{i+1}_f', 10**K[idx])\n",
    "        setattr(m, f'k{i+1}_r', 10**K[idx+1])\n",
    "\n",
    "    # last rate constant (k6_r) has cycle constraint\n",
    "    m.k6_f = 10**K[10]\n",
    "    m.k6_r = (m.k1_f*m.k2_f*m.k3_f*m.k4_f*m.k5_f*m.k6_f)/(m.k1_r*m.k2_r*m.k3_r*m.k4_r*m.k5_r)\n",
    "\n",
    "    try:\n",
    "        D_tmp = m.simulate(0, 5, 50, selections=['time', 'rxn4'])\n",
    "        y_tmp = D_tmp['rxn4'][1:]  # remove first point\n",
    "        sigma = 10**K[11]\n",
    "        log_like_tmp = calc_norm_log_like(y_tmp,sigma,y_obs)\n",
    "    except:\n",
    "        log_like_tmp = -np.inf  # if there is an issue calculating the flux --> no probability\n",
    "    return log_like_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pymc3 functions\n",
    "\n",
    "def normal_gradients(theta, data, m):\n",
    "    \"\"\"\n",
    "    Calculate the partial derivatives of a function at a set of values. The\n",
    "    derivatives are calculated using the central difference, using an iterative\n",
    "    method to check that the values converge as step size decreases.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    theta: array_like\n",
    "        A set of values, that are passed to a function, at which to calculate\n",
    "        the gradient of that function\n",
    "    x, data, sigma:\n",
    "        Observed variables as we have been using so far\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    grads: array_like\n",
    "        An array of gradients for each non-fixed value.\n",
    "    \"\"\"\n",
    "\n",
    "    grads = scipy.optimize.approx_fprime(theta, calc_log_like, 1.4901161193847656e-08, *(data,m))\n",
    "\n",
    "    return grads\n",
    "\n",
    "# define a aesara Op for our likelihood function\n",
    "class LogLikeWithGrad(at.Op):\n",
    "\n",
    "    \"\"\"\n",
    "    Specify what type of object will be passed and returned to the Op when it is\n",
    "    called. In our case we will be passing it a vector of values (the parameters\n",
    "    that define our model) and returning a single \"scalar\" value (the\n",
    "    log-likelihood)\n",
    "    \"\"\"\n",
    "\n",
    "    itypes = [at.dvector]  # expects a vector of parameter values when called\n",
    "    otypes = [at.dscalar]  # outputs a single scalar value (the log likelihood)\n",
    "\n",
    "    def __init__(self, loglike, data, m):\n",
    "        \"\"\"\n",
    "        Initialise the Op with various things that our log-likelihood function\n",
    "        requires. Below are the things that are needed in this particular\n",
    "        example.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        loglike:\n",
    "            The log-likelihood (or whatever) function we've defined\n",
    "        data:\n",
    "            The \"observed\" data that our log-likelihood function takes in\n",
    "        m:\n",
    "            Tellurium (libroadrunner) ODE model\n",
    "        \"\"\"\n",
    "\n",
    "        # add inputs as class attributes\n",
    "        self.likelihood = loglike\n",
    "        self.data = data\n",
    "        self.m = m\n",
    "\n",
    "        # initialise the gradient Op (below)\n",
    "        self.logpgrad = LogLikeGrad(self.data, self.m)\n",
    "\n",
    "    def perform(self, node, inputs, outputs):\n",
    "        # the method that is used when calling the Op\n",
    "        (theta,) = inputs  # this will contain my variables\n",
    "\n",
    "        # call the log-likelihood function\n",
    "        logl = self.likelihood(theta, self.data, self.m)\n",
    "\n",
    "        outputs[0][0] = np.array(logl)  # output the log-likelihood\n",
    "    \n",
    "    def grad(self, inputs, g):\n",
    "        # the method that calculates the gradients - it actually returns the\n",
    "        # vector-Jacobian product - g[0] is a vector of parameter values\n",
    "        (theta,) = inputs  # our parameters\n",
    "        return [g[0] * self.logpgrad(theta)]\n",
    "\n",
    "\n",
    "class LogLikeGrad(at.Op):\n",
    "    \n",
    "    \"\"\"\n",
    "    This Op will be called with a vector of values and also return a vector of\n",
    "    values - the gradients in each dimension.\n",
    "    \"\"\"\n",
    "\n",
    "    itypes = [at.dvector]\n",
    "    otypes = [at.dvector]\n",
    "\n",
    "    def __init__(self, data, m):\n",
    "        \"\"\"\n",
    "        Initialise with various things that the function requires. Below\n",
    "        are the things that are needed in this particular example.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        loglike:\n",
    "            The log-likelihood (or whatever) function we've defined\n",
    "        data:\n",
    "            The \"observed\" data that our log-likelihood function takes in\n",
    "        m:\n",
    "            Tellurium (libroadrunner) ODE model\n",
    "        \"\"\"\n",
    " \n",
    "\n",
    "        # add inputs as class attributes\n",
    "        self.data = data\n",
    "        self.m = m\n",
    "\n",
    "    def perform(self, node, inputs, outputs):\n",
    "        (theta,) = inputs\n",
    "\n",
    "        # calculate gradients\n",
    "        grads = normal_gradients(theta, self.data, self.m)\n",
    "\n",
    "        outputs[0][0] = grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "### utility functions\n",
    "def parse_p_info(p_info, near_global_min=True):\n",
    "    '''parse parameter settings data\n",
    "    p_info[i] = [parameter name, lower bound, upper bound, reference value]\n",
    "    '''\n",
    "    p_ref = [p_i[3] for p_i in p_info]\n",
    "    p_labels = [p[0] for p in p_info]\n",
    "    if near_global_min==True:\n",
    "        p_bounds = [(p[3]*0.999, p[3]*1.001) if p[3] > 0 else (p[3]*1.001, p[3]*0.999) for p in p_info]  # near global min\n",
    "    else:\n",
    "        p_bounds = [(p[1], p[2]) for p in p_info]  # default\n",
    "    return p_ref, p_labels, np.array(p_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "### input arguments\n",
    "model_file = \"/Users/georgeau/Desktop/GitHub/Bayesian_Transporter/transporter_model/antiporter_12D_model.txt\"\n",
    "obs_data_file = \"/Users/georgeau/Desktop/GitHub/Bayesian_Transporter/synthetic_data/synth_data_1exp_a_trunc_50s.csv\"\n",
    "parameter_file = \"/Users/georgeau/Desktop/GitHub/Bayesian_Transporter/transporter_model/12D_transporter_w_full_priors.json\"\n",
    "\n",
    "seed = 42\n",
    "near_global_min = False\n",
    "n_dim = 12\n",
    "n_steps = int(1e4)\n",
    "np.random.seed(seed)\n",
    "\n",
    "### file i/o - create new directory, load tellurium model string, and load model parameter info\n",
    "date_string = datetime.today().strftime('%Y%m%d_%H%M%S')\n",
    "out_fname=f'run_pymc4_d{date_string}_nd{n_dim}_ngm{near_global_min}_ns{n_steps}_r{seed}'\n",
    "current_directory = os.getcwd()\n",
    "final_directory = os.path.join(current_directory, out_fname)\n",
    "if not os.path.exists(final_directory):\n",
    "    os.makedirs(final_directory)\n",
    "with open(model_file, \"r\") as f:\n",
    "    antimony_string_SS = f.read()\n",
    "with open (parameter_file, 'rb') as fp:\n",
    "    p_info = json.load(fp)\n",
    "p_ref, p_labels, p_bounds = parse_p_info(p_info, near_global_min=near_global_min)\n",
    "_, _, p_bounds2 = parse_p_info(p_info, near_global_min=False)  # for plot (useful if starting near global max)\n",
    "\n",
    "### set log likelihood arguments and initial parameter sets\n",
    "y_obs= np.genfromtxt(obs_data_file)\n",
    "m = te.loada(antimony_string_SS)\n",
    "#p_0 = get_p0(p_bounds, n_walkers) \n",
    "\n",
    "### write to log file\n",
    "with open(os.path.join(final_directory, f'{out_fname}_log.txt'), \"a\") as f:\n",
    "    f.write(f\"date: {date_string}\\n\")\n",
    "    f.write(f\"model file: {model_file}\\n\")\n",
    "    f.write(f\"parameter file: {parameter_file}\\n\")\n",
    "    f.write(f\"data file: {obs_data_file}\\n\")\n",
    "    f.write(f\"seed: {seed}\\n\")\n",
    "    f.write(f\"n dim: {n_dim}\\n\")\n",
    "    f.write(f\"n steps: {n_steps}\\n\")\n",
    "    f.write(f\"near global min: {near_global_min}\\n\")\n",
    "    f.write(f\"out fname: {out_fname}\\n\")\n",
    "    f.write(f\"parameter ref: {p_ref}\\n\")\n",
    "    f.write(f\"parameter labels: {p_labels}\\n\")\n",
    "    f.write(f\"parameter boundaries: {p_bounds}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "/opt/miniconda3/envs/pyMC4_env/lib/python3.10/site-packages/pymc/aesaraf.py:1005: UserWarning:\n",
      "\n",
      "The parameter 'updates' of aesara.function() expects an OrderedDict, got <class 'dict'>. Using a standard dictionary here results in non-deterministic behavior. You should use an OrderedDict if you are using Python 2.7 (collections.OrderedDict for older python), or use a list of (shared, update) pairs. Do not just convert your dictionary to this type before the call as the conversion will still be non-deterministic.\n",
      "\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [log_k1_f, log_k1_r, log_k2_f, log_k2_r, log_k3_f, log_k3_r, log_k4_f, log_k4_r, log_k5_f, log_k5_r, log_k6_f, log_sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='617' class='' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      30.85% [617/2000 05:46&lt;12:57 Sampling chain 0, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/pyMC4_env/lib/python3.10/site-packages/scipy/optimize/_numdiff.py:576: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in subtract\n",
      "\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.86597e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.86597e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.86597e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.86597e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.86597e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.86597e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.86597e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.86597e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.86597e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.86597e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.86597e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.86597e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.86597e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.86597e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.51271e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.51271e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.51271e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.51271e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.51271e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.51271e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.51271e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.51271e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.51271e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.51271e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.51271e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.51271e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.51271e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.51271e-29, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.1681e-27, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.1681e-27, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.1681e-27, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.1681e-27, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.1681e-27, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.1681e-27, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.1681e-27, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.1681e-27, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.1681e-27, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.1681e-27, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.1681e-27, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.1681e-27, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.1681e-27, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n",
      "\u001b[35mError: CVODE Error: CV_ERR_FAILURE, Module: CVODES, Function: CVode, Message: At t = 0 and h = 1.1681e-27, the error test failed repeatedly or with |h| = hmin.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### pyMC4 sampling\n",
    "\n",
    "# create our Op\n",
    "logl = LogLikeWithGrad(calc_log_like, y_obs, m)\n",
    "\n",
    "# use PyMC to sampler from log-likelihood\n",
    "with pm.Model() as opmodel:\n",
    "    # uniform priors on m and c\n",
    "    p_0 = pm.Uniform(f\"{p_labels[0]}\", lower=p_bounds[0][0], upper=p_bounds[0][1])\n",
    "    p_1 = pm.Uniform(f\"{p_labels[1]}\", lower=p_bounds[1][0], upper=p_bounds[1][1])\n",
    "    p_2 = pm.Uniform(f\"{p_labels[2]}\", lower=p_bounds[2][0], upper=p_bounds[2][1])\n",
    "    p_3 = pm.Uniform(f\"{p_labels[3]}\", lower=p_bounds[3][0], upper=p_bounds[3][1])\n",
    "    p_4 = pm.Uniform(f\"{p_labels[4]}\", lower=p_bounds[4][0], upper=p_bounds[4][1])\n",
    "    p_5 = pm.Uniform(f\"{p_labels[5]}\", lower=p_bounds[5][0], upper=p_bounds[5][1])\n",
    "    p_6 = pm.Uniform(f\"{p_labels[6]}\", lower=p_bounds[6][0], upper=p_bounds[6][1])\n",
    "    p_7 = pm.Uniform(f\"{p_labels[7]}\", lower=p_bounds[7][0], upper=p_bounds[7][1])\n",
    "    p_8 = pm.Uniform(f\"{p_labels[8]}\", lower=p_bounds[8][0], upper=p_bounds[8][1])\n",
    "    p_9 = pm.Uniform(f\"{p_labels[9]}\", lower=p_bounds[9][0], upper=p_bounds[9][1])\n",
    "    p_10 = pm.Uniform(f\"{p_labels[10]}\", lower=p_bounds[10][0], upper=p_bounds[10][1])\n",
    "    p_11 = pm.Uniform(f\"{p_labels[11]}\", lower=p_bounds[11][0], upper=p_bounds[11][1])\n",
    "    p_list = [p_0, p_1, p_2, p_3, p_4, p_5, p_6, p_7, p_8, p_9, p_10, p_11]\n",
    "\n",
    "    # convert m and c to a tensor vector\n",
    "    theta = at.as_tensor_variable(p_list)\n",
    "\n",
    "    # use a Potential to \"call\" the Op and include it in the logp computation\n",
    "    pm.Potential(\"likelihood\", logl(theta))\n",
    "\n",
    "    # Use custom number of draws to replace the HMC based defaults\n",
    "    idata_grad = pm.sample(chains=1)\n",
    "\n",
    "# plot the traces\n",
    "az.plot_trace(idata_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('pyMC4_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d0dbcc5fdb3083d74eda216ce346df03dd9cae5d97de138eef36e59b6673b05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
